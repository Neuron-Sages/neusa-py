{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-06T15:22:52.906984Z","iopub.status.busy":"2023-07-06T15:22:52.906311Z"},"trusted":true},"outputs":[],"source":["!pip install -Uqq pyts fastbook pandas-ta"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# Import necessary libraries\n","import datetime as dt\n","import os\n","import warnings\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import numpy as np\n","import pandas as pd\n","import pywt\n","import pywt.data\n","import re\n","import gc\n","import pandas_ta as ta\n","from pyts.image import GramianAngularField\n","from PIL import Image as im\n","%matplotlib inline \n","\n","import fastbook\n","fastbook.setup_book()\n","from fastbook import *\n","import matplotlib.image\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["SYMBOL = 'BTCUSDT'\n","INTERVAL = '1m'\n","INPUT_SIZE = 30\n","RAW_INPUT_SIZE = 100\n","THRESHOLD = 0.97\n","TRADING_PERCENT = 0.1\n","INITIAL_USD_BALANCE = 1000\n","STOP_PROFIT = 0.004\n","STOP_LOSS = 0.004\n","ORDER_LIFE = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wavelet_type = 'sym15'\n","w = pywt.Wavelet(wavelet_type)\n","def denoise(data):\n","    if len(data) > 0:\n","        maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n","        coeffs = pywt.wavedec(data, wavelet_type, level=maxlev)\n","        coeffs[-1] = np.zeros_like(coeffs[-1])\n","        datarec = pywt.waverec(coeffs, wavelet_type)\n","        return datarec\n","    else:\n","        return data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/binance-1m/binance.csv\", header=0, names=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n","df['timestamp'] = df['timestamp'].apply(lambda x: pd.to_datetime(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def calc_label(dataset, position):\n","    price = dataset['close'].to_numpy()[position]\n","    stop_loss = STOP_LOSS * price\n","    stop_profit = STOP_PROFIT * price\n","    label = \"wait\"\n","    bearish_stop_loss = price + stop_loss\n","    bearish_stop_profit = price - stop_profit\n","    bullish_stop_loss = price - stop_loss\n","    bullish_stop_profit = price + stop_profit\n","    for i in range(1, ORDER_LIFE+1):\n","        max_price = dataset['high'].to_numpy()[position+i]\n","        low_price = dataset['low'].to_numpy()[position+i]\n","        if low_price > bullish_stop_loss:\n","            if max_price >= bullish_stop_profit:\n","                label = \"buy\"\n","                break\n","        else:\n","            break\n","    for i in range(1, ORDER_LIFE+1):\n","        max_price = dataset['high'].to_numpy()[position+i]\n","        low_price = dataset['low'].to_numpy()[position+i]\n","        if max_price < bearish_stop_loss:\n","            if low_price <= bearish_stop_profit:\n","                label = \"sell\"\n","                break\n","        else:\n","            break\n","    return label\n","        \n","       \n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["L = len(df['close'])\n","df_labels = [None]*L\n","for i in range(0, L-ORDER_LIFE):\n","    df_labels[i] = calc_label(df, i)\n","\n","df_labeled_raw = df.copy()\n","df_labeled_raw['label'] = df_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","df = df_labeled_raw.iloc[:-ORDER_LIFE].reset_index(drop=True).copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"source":["DS_LENGTH = len(df['close'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_open = [None]*DS_LENGTH\n","input_high = [None]*DS_LENGTH\n","input_low = [None]*DS_LENGTH\n","input_close = [None]*DS_LENGTH\n","input_volume = [None]*DS_LENGTH\n","input_timestamp = [None]*DS_LENGTH\n","for i in range(0, DS_LENGTH):\n","    if i + 1 >= RAW_INPUT_SIZE:\n","        input_open[i] = df.iloc[i+1-RAW_INPUT_SIZE:i+1].open.copy()\n","        input_high[i] = df.iloc[i+1-RAW_INPUT_SIZE:i+1].high.copy()\n","        input_low[i] = df.iloc[i+1-RAW_INPUT_SIZE:i+1].low.copy()\n","        input_close[i] = df.iloc[i+1-RAW_INPUT_SIZE:i+1].close.copy()\n","        input_volume[i] = df.iloc[i+1-RAW_INPUT_SIZE:i+1].volume.copy()\n","        input_timestamp[i] = df.iloc[i+1-RAW_INPUT_SIZE:i+1].timestamp.copy().reset_index(drop=True)\n","df['input_open'] = input_open\n","df['input_high'] = input_high\n","df['input_low'] = input_low\n","df['input_close'] = input_close\n","df['input_volume'] = input_volume\n","df['input_timestamp'] = input_timestamp\n","df = df.iloc[RAW_INPUT_SIZE:].copy().reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = df[df['label'] != 'wait'].reset_index(drop=True).copy()\n","df.drop(columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n","df = df.copy()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["DS_LENGTH = len(df['input_close'])\n","denoised_input_open = [None]*DS_LENGTH\n","denoised_input_high = [None]*DS_LENGTH\n","denoised_input_low = [None]*DS_LENGTH\n","denoised_input_close = [None]*DS_LENGTH\n","denoised_input_volume = [None]*DS_LENGTH\n","\n","for i in range(0, DS_LENGTH):\n","    denoised_input_open[i] = denoise(df['input_open'][i])\n","    denoised_input_high[i] = denoise(df['input_high'][i])\n","    denoised_input_low[i] = denoise(df['input_low'][i])\n","    denoised_input_close[i] = denoise(df['input_close'][i])\n","    denoised_input_volume[i] = denoise(df['input_volume'][i])\n","\n","df['denoised_input_open'] = denoised_input_open\n","df['denoised_input_high'] = denoised_input_high\n","df['denoised_input_low'] = denoised_input_low\n","df['denoised_input_close'] = denoised_input_close\n","df['denoised_input_volume'] = denoised_input_volume\n","df.drop(columns=['input_open', 'input_high', 'input_low', 'input_close', 'input_volume'])\n","df = df.copy()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ind_list = ['qstick', 't3', 'cti', 'mad', 'ha', 'squeeze', 'aroon', 'bbands', 'kc', 'vwap', 'stoch'] #df.ta.indicators(as_list=True)\n","#indies_partition_size = 10\n","#p_ind_list = [ind_list[i:i + indies_partition_size] for i in range(0, len(ind_list), indies_partition_size)]\n","ind_columns = ['qstick', 't3', 'cti', 'mad', 'HA_low', 'SQZ_20_2.0_20_1.5', 'AROONU_14', 'BBU_5_2.0', 'KCBe_20_2', 'vwap', 'STOCHd_14_3_3']\n","#p_ind_list\n","#exclude_indies = ['above', 'above_value', 'open', 'high', 'low', 'close', 'volume']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for indi in ind_list:\n","    indi_result = {}\n","    new_cols = []\n","    for i in range(0, DS_LENGTH):\n","        indi_input = pd.DataFrame()\n","        indi_input['open'] = df['denoised_input_open'][i].copy()\n","        indi_input['high'] = df['denoised_input_high'][i].copy()\n","        indi_input['low'] = df['denoised_input_low'][i].copy()\n","        indi_input['close'] = df['denoised_input_close'][i].copy()\n","        indi_input['volume'] = df['denoised_input_volume'][i].copy()\n","        indi_input['timestamp'] = df['input_timestamp'][i].copy(\n","        ).reset_index(drop=True)\n","        indi_input.set_index(pd.DatetimeIndex(\n","            indi_input[\"timestamp\"]), inplace=True)\n","        indi_fn = getattr(indi_input.ta, indi)\n","        data = indi_fn()\n","        if len(new_cols) == 0:\n","            if not isinstance(data, pd.Series):\n","                new_cols = new_cols + data.columns.to_numpy().tolist()\n","            else:\n","                new_cols = new_cols + [indi]\n","            for col_name in new_cols:\n","                indi_result[col_name] = [None]*DS_LENGTH\n","        for col_name in new_cols:\n","            if not isinstance(data, pd.Series):\n","                indi_result[col_name][i] = data[col_name]\n","            else:\n","                indi_result[col_name][i] = data\n","    for col_name in new_cols:\n","        if col_name in ind_columns:\n","            df[col_name] = indi_result[col_name]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gaf_transformer = GramianAngularField(method='difference', image_size=INPUT_SIZE)\n","df_gaf_input_open = [None]*DS_LENGTH\n","df_gaf_input_high = [None]*DS_LENGTH\n","df_gaf_input_low = [None]*DS_LENGTH\n","df_gaf_input_close = [None]*DS_LENGTH\n","df_gaf_input_volume = [None]*DS_LENGTH\n","for i in range(0, DS_LENGTH):\n","    if len(df['denoised_input_close'][i]) > 0:\n","        df_gaf_input_open[i] = gaf_transformer.fit_transform(df['denoised_input_open'][i][-INPUT_SIZE:].reshape(1, -1))\n","        df_gaf_input_high[i] = gaf_transformer.fit_transform(df['denoised_input_high'][i][-INPUT_SIZE:].reshape(1, -1))\n","        df_gaf_input_low[i] = gaf_transformer.fit_transform(df['denoised_input_low'][i][-INPUT_SIZE:].reshape(1, -1))\n","        df_gaf_input_close[i] = gaf_transformer.fit_transform(df['denoised_input_close'][i][-INPUT_SIZE:].reshape(1, -1))\n","        df_gaf_input_volume[i] = gaf_transformer.fit_transform(df['denoised_input_volume'][i][-INPUT_SIZE:].reshape(1, -1))\n","df['gaf_open'] = df_gaf_input_open\n","df['gaf_high'] = df_gaf_input_high\n","df['gaf_low'] = df_gaf_input_low\n","df['gaf_close'] = df_gaf_input_close\n","df['gaf_volume'] = df_gaf_input_volume\n","df.drop(columns=['denoised_input_open', 'denoised_input_high', 'denoised_input_low', 'denoised_input_close', 'denoised_input_volume', 'input_timestamp'])\n","df = df.copy()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for col_name in ind_columns:\n","    print(col_name)\n","    gaf_col = [None]*DS_LENGTH\n","    for i in range(0, DS_LENGTH):\n","        if len(df['denoised_input_close'][i]) > 0:\n","            if isinstance(df[col_name][i], pd.Series):\n","                gaf_col[i] = gaf_transformer.fit_transform(\n","                    df[col_name][i][-INPUT_SIZE:].to_numpy().reshape(1, -1))\n","            else:\n","                gaf_col[i] = gaf_transformer.fit_transform(\n","                    df[col_name][i][-INPUT_SIZE:].reshape(1, -1))\n","    df[col_name] = gaf_col"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_train = df.copy()\n","gc.collect()\n","pat = r'^(.*)_\\d+.png'\n","images_path = '/kaggle/working/images/'\n","if not os.path.exists(images_path):\n","    os.makedirs(images_path)\n","files = get_image_files(images_path)\n","for f in files:\n","    os.remove(f)\n","files = get_image_files(images_path)\n","L = len(df_train['gaf_open'])\n","for i in range(0, L):\n","    i_open = df_train['gaf_open'].to_numpy()[i].squeeze()\n","    i_high = df_train['gaf_high'].to_numpy()[i].squeeze()\n","    i_low = df_train['gaf_low'].to_numpy()[i].squeeze()\n","    i_close = df_train['gaf_close'].to_numpy()[i].squeeze()\n","    i_volume = df_train['gaf_volume'].to_numpy()[i].squeeze()\n","    inputs_list = [i_open, i_high, i_low, i_close, i_volume] + [df_train[col_name].to_numpy()[i].squeeze() for col_name in ind_columns]\n","    rows_list = [inputs_list[i:i + 4] for i in range(0, len(inputs_list), 4)]\n","    image_rows = [np.concatenate(row) for row in rows_list]\n","    image = np.concatenate(image_rows, axis=1)\n","    label = df_train['label'].to_numpy()[i]\n","    matplotlib.image.imsave(images_path + label + '_' + str(i) + '.png', image)\n","files = get_image_files(images_path)\n","dls = ImageDataLoaders.from_name_re(images_path, files, pat)\n","#dls.show_batch()\n","learn = vision_learner(dls, resnet34, metrics=error_rate)\n","\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#learn.lr_find()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["learn.fine_tune(20, 0.001737800776027143) #resnet34 the best so far"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","#learn.show_results()\n","#learn.predict(files[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#learn.export(fname='/kaggle/working/model.pkl')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
